### End to End SGD

We've learned how to calculate the gradients to find a local minimum.

Next, let's see them in the context of a model.

The example in the book talks about a roller coast, and measuring the speed. Like if it were to go over the top of a hump. Basically, it would slow down as the slop increased, and then speed up as the slope decreased.

![[Screenshot 2024-01-23 at 5.46.48 PM.png]]

How would you find the roller coasters speed? You could use SGD!

Here's what Jeremy Says: 

> Using SGD we can try to find a function that matches our observations. We can't consider every possible function, so let's use a guess that it will be quadratic; i.e., a function of the form `a*(time**2)+(b*time)+c`

> We want to distinguish clearly between the function's input (the time when we are measuring the coaster's speed) and its parameters (the values that define _which_ quadratic we're trying). So, let's collect the parameters in one argument and thus separate the input, `t`, and the parameters, `params`, in the function's signature:

```python
def f(t, params): # t is the time, and the position we are trying to estimate
	a,b,c = params # params to get from function and tweak
	return a*(t**2) + (b*t) + c
```

We've gone from finding the BEST function to finding the best QUADRATIC function here. That means that the only parameters we need to tweak are a,b, and c as they are the only arguments that actually represent the problem. Cool!

What BEST means is subjective, and something we need to make concrete with a loss function.

We need to return lower values when predictions are more accurate using the loss function, as the Stochastic Gradient Descent needs to minimize this loss.

For continuous data, it's common to use _mean squared error_. We defined this earlier, and also called it L2 Loss.

```python
def mse(preds, targets): return ((preds-targets)**2).mean()
```

Let's run through the steps:

###### Step 1: Initialize the Parameters

We first initialize parameters to random values, and tell Pytorch that we want to track their gradients using `requires_grad_()`

```Python
params = torch.randn(3).requires_grad_()
```

###### Step 2: Calculate the Predictions
 
 Next, let's calculate the actual predictions

```python
preds = f(time, params)
```

here's a function to show the actual predictions here

```python
def show_preds(preds, ax=None):
	if ax is None: ax=plt.subplots()[1]
	ax.scatter(time, speed)
	ax.scatter(time, to_np(preds), color='red')
	ax.set_ylim(-300,100)
```

![[Screenshot 2024-01-23 at 5.56.54 PM.png]]

These are super different!

###### Step 3: Calculate the Loss

Let's use MSE (L2) to calculate the loss

```python
loss = mse(preds,speed)
loss # tensor(25823.8086, grad_fn=<MeanBackward0>)
```

Now we need to improve, as we have our loss, of MSE from the predictions and the actual values.

###### Step 4: Calculate the Gradients

Gradients are an approximation of how parameters need to change

```python
loss.backward()
params.grad # tensor([-53195.8594,  -3419.7146,   -253.8908])
```

```python
params # tensor([-0.7658, -0.7506,  1.3525], requires_grad=True)
```

These gradients are what we use to improve the parameters! Let's pick a learning rate to step the weights! (like above)

###### Step 5: Step the weights

```python
lr = 1e-5 # learning rate
params.data -= lr * params.grad.data
params.grad = None
```

Let's break this down, step by step. To calculate the gradients, we call the Pytorch method `.backward()` on the loss. However, the loss was calculated by the loss function, in this case MSE (L2). 

MSE took the `preds` as input, which was calculated using the quadratic prediction function `f` we initialized with random values. It took in `params` as and input, which was the object that we originally called `requires_grad`. THIS is what allows us to call `.backward()` on the `loss`. This chain of function calls represents the math composition of functions -> enables PyTorch to use [[Calculus]] [[Chain Rule]] under the hood to calculate the gradients.

Let's repeat a few times so we can create function to apply a single step.

```python
def apply_step(params, prn=True): # 
	preds = f(time, params)
	loss = mse(preds, speed)
	loss.backward()
	params.data -= lr * params.grad.data
	params.grad = None
	if prn: print(loss.item())
	return preds
```

###### Step 6: Repeat Steps

Let's iterate through each step (defined above). By looping over and performing improvements, we will get a basic idea of how we will improve the models functions "fit" to the model.

```python
for i in range(10): apply_step(params)
```

![[Screenshot 2024-01-23 at 6.14.46 PM.png]]

###### Step 7: Stop

For now, we are stopping after 10 iterations (see above), but in practice, we might watch the training and validation losses and let the metrics tell us when to stop.
### Summarizing Gradient Descent

![[Screenshot 2024-01-23 at 6.16.06 PM.png]]

To start, model weights can be random (training from scratch, or come pretrained (transfer learning).

We begin by comparing the outputs from the base model of sample data (training data) with our ground truth using a loss function.

This returns a number we want to reduce. The higher the loss, the more error, or distance between the predictions and the ground truth.

To make a better next prediction, we take the loss, and calculate the gradients using calculus.