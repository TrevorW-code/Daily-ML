## The MNIST Loss Function

> We already have our independent variables `x`—these are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using `view`, which is a PyTorch method that changes the shape of a tensor without changing its contents. `-1` is a special parameter to `view` that means "make this axis as big as necessary to fit all the data":

```Python
train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)
```

^ This is interesting to me. What we are doing in concatenating them into a single tensor. How are we concatenating? We are essentially flattening all images in a new shape as a batch of 784 (28 * 28), and then concatenating each individual image back into one tensor

[Pytorch Cat Documentation](https://pytorch.org/docs/stable/generated/torch.cat.html)
[Pytorch View Documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)

```python
train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)
train_x.shape,train_y.shape
```

Next up we create the labels in binary. 3s = 1, and 7s = 0. We take the flattened list wrapped in the tensor method, and "unsqueeze it" so we can return a transposed version of the tensor (labels aligning with the concatenated images)

[Pytorch Unsqueeze Documentation](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html)

Datasets in Pytorch require taking tuples (x,y) when indexed. We can do this using python zip function, and when combining it with list, it makes it easy to format our data this way.

```python
dset = list(zip(train_x,train_y))
x,y = dset[0]
x.shape,y
```

Next, we create the validation data:

```python
valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)
valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)
valid_dset = list(zip(valid_x,valid_y))
```

THEN we initialize the weights for every pixel at random! (The beginning of SGD!)

```python
def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() # function to create the random weights

weights = init_params((28_28),1) # sample weights
```

The function `weights x pixels` is NOT flexible enough - it is always equal to 0 when pixels are equal to 0 (its intercept is 0). 

In HS, remember that the formula for a line is `y=w*x+b`. We still need b, and we'll randomize that too

> In neural networks, the `w` in the equation `y=w*x+b` is called the _weights_, and the `b` is called the _bias_. Together, the weights and bias make up the _parameters_.

Finally, let's calculate a prediction for one image:

```python
(train_x[0]*weights.T).sum() + bias
# tensor([20.2336], grad_fn=<AddBackward0>)
```

> While we could use a Python `for` loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.

> In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix—it's called _[[matrix multiplication]]_. <> shows what matrix multiplication looks like.

This is the [[Linear Algebra]] section of this.

![[Screenshot 2024-01-24 at 6.16.55 PM.png]]

Here's a refresher todo: [Intro to Matrix Multiplication](https://youtu.be/kT4Mp9EdVqs) 

^ This is the most important mathematical operation in deep learning!

> In Python, matrix multiplication is represented with the `@` operator. Let's try it:

```python
def linear1(xb): return xb@weights + bias
preds = linear1(train_x)
preds

# tensor([[20.2336],
#        [17.0644],
#        [15.2384],
#        ...,
#        [18.3804],
#        [23.8567],
#        [28.6816]], grad_fn=<AddBackward0>)
```

You can see that earlier, the first value in this tensor was the value of the prediction code in the cell before. This equation above `batch@weights + bias` is one of the most fundamental equations of any neural network.

The other is the _[[activation function]]_!

> Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, so our accuracy for each item can be calculated (using broadcasting, so no loops!) with:

```python
corrects = (preds>0.0).float() == train_y
corrects # returns a tensor of True and False
```

```python
corrects.float().mean().item()
```

^ this above calculates the mean. Interesting.

> Now let's see what the change in accuracy is for a small change in one of the weights (note that we have to ask PyTorch not to calculate gradients as we do this, which is what `with torch.no_grad()` is doing here):

```python
with torch.no_grad(): weights[0] *= 1.0001 # changing the weights, please don't calc gradients
preds = linear1(train_x)
((preds>0.0).float() == train_y).float().mean().item()
# Without the gradient
```

> As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some *loss function* that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.

SO basically, [[Gradients]] show how the [[Loss Functions]] changes with the updates to the weights. Cool.

This next section is a little confusing, but bear with me.

Using Accuracy as a loss metric will not work. Calculating an overall accuracy, and using that to calculate gradients with respect to each individual weight will not work. Here's the explanation

> The gradient of a function is its *slope*, or its steepness, which can be defined as *rise over run*—that is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: `(y_new - y_old) / (x_new - x_old)`. This gives us a good approximation of the gradient when `x_new` is very similar to `x_old`, meaning that their difference is very small. But accuracy only changes at all when a prediction changes from a 3 to a 7, or vice versa. The problem is that a small change in weights from `x_old` to `x_new` isn't likely to cause any prediction to change, so `(y_new - y_old)` will almost always be 0. In other words, the gradient is 0 almost everywhere.

Essentially, because there is no real change in predictions (as a result of using accuracy as a loss function), weights don't change. Ever.

> A very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss function—if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number

The better method hear is to compare predictions from the model to the ground truth.

Here's an example

| Numbers | 3 | 7 | 3 |
| ---- | ---- | ---- | ---- |
| Model Label Prediction | 0.9 | 0.4 | 0.2 |
| Real Label | 1 | 0 | 1 |

So, what can we do with this information?

Let's try defining the loss like this:

```python
def mnist_loss(predictions, targets):
	return torch.where(targers==1,1-predictions,predictions).mean()
```

What's going on here?

> We're using a new function, `torch.where(a,b,c)`. This is the same as running the list comprehension `[b[i] if a[i] else c[i] for i in range(len(a))]`, except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances.

Okay, going to try to paraphrase. so, for condition a, if A is True, make the value B. Else, Make the value C.

This is HUGE!

[Pytorch Where Documentation](https://pytorch.org/docs/stable/generated/torch.where.html)

Let's try this out:

```python
torch.where(trgts==1, 1-prds, prds)
# tensor([0.1000, 0.4000, 0.8000])
```

Essentially, the the number returns a lower score (lower loss) when the model is closer, and further when the model is more wrong. This seems promising!

However, we need to make sure that all of our predictions are between 0 and 1! What function can we use to squish all numbers between 0 and 1?

### Sigmoid Function

This function always outputs numbers between 0 and 1:

Here's it's definition:

```python
def sigmoid(x): return 1/(1+torch.exp(-x))
```

![[Screenshot 2024-01-24 at 7.00.21 PM.png]]

This is the curvy boi. We love this guy, as he is super important in NN.

It's also a smooth curve that only goes up, which makes it easier for SGD to find meaningful gradients.

Let's Recap the difference between Loss, and Metrics like Accuracy

> The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.

To be Continued!